{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **HW3.2:  Regression with Decision Trees**  \n",
        "\n",
        "(Cập nhật lần cuối: 4/5/2025)  \n",
        "\n",
        "Họ tên: Nguyễn Lê Tấn Phát  \n",
        "\n",
        "MSSV: 22120262\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "ZVSDF9C-VoMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prepare enviroment**"
      ],
      "metadata": {
        "id": "K_KWoGRBcgQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install java\n",
        "!apt-get updatec\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.5.5-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "revQ3r69VoqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set your spark folder to your system path environment.\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.5-bin-hadoop3\""
      ],
      "metadata": {
        "id": "bCM_ua_lVucB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start pyspark\n",
        "!pip install findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "UksomsxAVvfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local\")\\\n",
        "          .appName(\"Spark APIs Exercises\")\\\n",
        "          .config(\"spark.some.config.option\", \"some-value\")\\\n",
        "          .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "tiBYFrI_Vw1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "from pyspark.ml.feature import VectorIndexer\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql.functions import hour, dayofweek, month\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
        "from pyspark.mllib.util import MLUtils\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.mllib.linalg import Vectors\n",
        "\n",
        "import datetime"
      ],
      "metadata": {
        "id": "jrbeCh5ncahV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prepare data**"
      ],
      "metadata": {
        "id": "EdWlG4D_V1pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "id": "3kpWFJOchgnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.2.1: Structured API Implementation (High-Level)**"
      ],
      "metadata": {
        "id": "4lfTkpN-zd5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "5Sb3wD4yzg4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_rawData = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n",
        "test_rawData = spark.read.csv(\"test.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "MH0GMi2QV4eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-val split"
      ],
      "metadata": {
        "id": "qTNXgccYfH7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_df, val_df) = train_rawData.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "gkByEGhPfFtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-process data"
      ],
      "metadata": {
        "id": "ifIFjkeVXH7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop id column (This is not necessary when training)"
      ],
      "metadata": {
        "id": "jSWl2fKRv4CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop(\"id\")\n",
        "val_df = val_df.drop(\"id\")\n",
        "test_df = test_rawData.drop(\"id\")"
      ],
      "metadata": {
        "id": "pde5IHFbvNoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle `pickup_datetime` column which have timestamp data type"
      ],
      "metadata": {
        "id": "HIpLuxS4zl7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for df in [train_df, val_df, test_df]:\n",
        "    df = df.withColumn(\"pickup_hour\", hour(df[\"pickup_datetime\"]))\n",
        "    df = df.withColumn(\"pickup_dayofweek\", dayofweek(df[\"pickup_datetime\"]))\n",
        "    df = df.withColumn(\"pickup_month\", month(df[\"pickup_datetime\"]))\n",
        "\n",
        "train_df = train_df.drop(\"pickup_datetime\", \"dropoff_datetime\")\n",
        "val_df = val_df.drop(\"pickup_datetime\", \"dropoff_datetime\")\n",
        "test_df = test_df.drop(\"pickup_datetime\", \"dropoff_datetime\")"
      ],
      "metadata": {
        "id": "kqyRsLrYvULg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle `store_and_fwd_flag` column which have string data type"
      ],
      "metadata": {
        "id": "xDYHKohRzzy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indexer = StringIndexer(inputCol=\"store_and_fwd_flag\", outputCol=\"store_and_fwd_flag_index\")\n",
        "train_df = indexer.fit(train_df).transform(train_df).drop(\"store_and_fwd_flag\")\n",
        "val_df = indexer.fit(val_df).transform(val_df).drop(\"store_and_fwd_flag\")\n",
        "test_df = indexer.fit(test_df).transform(test_df).drop(\"store_and_fwd_flag\")"
      ],
      "metadata": {
        "id": "6H-yNKs-vaUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove label column"
      ],
      "metadata": {
        "id": "PsVl99BrfXma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputCols = [col for col in train_df.columns if col != \"trip_duration\"]"
      ],
      "metadata": {
        "id": "8uQwrbjUfeDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assemble numeric feature"
      ],
      "metadata": {
        "id": "lPJvNdncfivg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")"
      ],
      "metadata": {
        "id": "lwEq5Y9qfncM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature indexing - handle categorical features automatically"
      ],
      "metadata": {
        "id": "npNjshY4frYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_indexer = VectorIndexer(\n",
        "    inputCol=\"features\",\n",
        "    outputCol=\"indexedFeatures\",\n",
        "    maxCategories=4  # Features with ≤4 distinct values are treated as categorical\n",
        ").fit(assembler.transform(train_df))"
      ],
      "metadata": {
        "id": "74eTPUU6fuT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Decision Tree Regressor model using MLlib"
      ],
      "metadata": {
        "id": "diwYQnj4ZPdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Decision Tree model with parameters"
      ],
      "metadata": {
        "id": "ocAwQun_gMoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeRegressor(\n",
        "    featuresCol=\"indexedFeatures\",\n",
        "    labelCol=\"trip_duration\",\n",
        "    maxDepth=5,                     # Control model complexity\n",
        "    minInstancesPerNode=10,         # Prevent overfitting\n",
        "    impurity=\"variance\"             # Variance for regression\n",
        ")"
      ],
      "metadata": {
        "id": "7E9-DtZfZsOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create pipeline"
      ],
      "metadata": {
        "id": "9za1yrKogQjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=[\n",
        "    assembler,\n",
        "    feature_indexer,\n",
        "    dt\n",
        "])"
      ],
      "metadata": {
        "id": "P9XsBS0WgRnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "VjF3o4m3gjwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(train_df)"
      ],
      "metadata": {
        "id": "SCE8n8Okggeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions on validation"
      ],
      "metadata": {
        "id": "YWc_P_8uguZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_predictions = model.transform(val_df)"
      ],
      "metadata": {
        "id": "82WXu7pSgu5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation model"
      ],
      "metadata": {
        "id": "AZv5hsxtg60v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create evaluators for different metrics"
      ],
      "metadata": {
        "id": "iHqJG4Pry9Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_evaluator = RegressionEvaluator(\n",
        "    labelCol=\"trip_duration\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"rmse\"\n",
        ")\n",
        "\n",
        "r2_evaluator = RegressionEvaluator(\n",
        "    labelCol=\"trip_duration\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"r2\"\n",
        ")"
      ],
      "metadata": {
        "id": "gmtf0wJfzBVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze model structure and feature importance"
      ],
      "metadata": {
        "id": "v3QJsSpgzNpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_model = model.stages[2]  # DecisionTreeRegressor is the 3rd stage in pipeline\n",
        "\n",
        "print(\"\\nDecision Tree Model Summary:\")\n",
        "print(\"Depth:\", tree_model.depth)\n",
        "print(\"Number of Nodes:\", tree_model.numNodes)\n",
        "print(\"Feature importances:\")\n",
        "for col, imp in zip(inputCols, tree_model.featureImportances):\n",
        "    print(f\"- {col}: {imp:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYXa58MvzO_o",
        "outputId": "8faf8ffa-415c-4d65-e5ea-45615b2ccb3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree Model Summary:\n",
            "Depth: 5\n",
            "Number of Nodes: 63\n",
            "Feature importances:\n",
            "- vendor_id: 0.04\n",
            "- passenger_count: 0.00\n",
            "- pickup_longitude: 0.33\n",
            "- pickup_latitude: 0.10\n",
            "- dropoff_longitude: 0.33\n",
            "- dropoff_latitude: 0.20\n",
            "- store_and_fwd_flag_index: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on validation set"
      ],
      "metadata": {
        "id": "93L8fl3WzDLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_rmse = rmse_evaluator.evaluate(val_predictions)\n",
        "val_r2 = r2_evaluator.evaluate(val_predictions)"
      ],
      "metadata": {
        "id": "701xUNSrzE0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nModel Evaluation Results:\")\n",
        "print(\"Validation Set:\")\n",
        "print(\"Root Mean Squared Error (RMSE) =\", val_rmse)\n",
        "print(\"R-squared (R²) =\", val_r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y4i6SC_zLem",
        "outputId": "fd294bcb-e4ae-4bd8-b9e6-570927bfa917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Evaluation Results:\n",
            "Validation Set:\n",
            "Root Mean Squared Error (RMSE) = 4927.6391800412175\n",
            "R-squared (R²) = 0.00806711612677502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.2.2: MLlib RDD-Based Implementation**"
      ],
      "metadata": {
        "id": "Lhjgqp2y1tC4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "5HhYGYh229vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines = sc.textFile(\"train.csv\")\n",
        "train_header = train_lines.first()\n",
        "train_rawData = train_lines.filter(lambda line: line != train_header)\n",
        "\n",
        "test_lines = sc.textFile(\"train.csv\")\n",
        "test_header = test_lines.first()\n",
        "test_rawData = test_lines.filter(lambda line: line != test_header)"
      ],
      "metadata": {
        "id": "V0xMBV3X1vTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parsing and pre-process the data file"
      ],
      "metadata": {
        "id": "owWNa4dVix-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse(row):\n",
        "    try:\n",
        "        parts = row.split(\",\")\n",
        "        vendor_id = float(parts[1])\n",
        "        pickup_dt = datetime.datetime.strptime(parts[2].strip(), \"%Y-%m-%d %H:%M:%S\")\n",
        "        dropoff_dt = datetime.datetime.strptime(parts[3].strip(), \"%Y-%m-%d %H:%M:%S\")\n",
        "        passenger_count = float(parts[4])\n",
        "        pickup_long = float(parts[5])\n",
        "        pickup_lat = float(parts[6])\n",
        "        dropoff_long = float(parts[7])\n",
        "        dropoff_lat = float(parts[8])\n",
        "        store_fwd = 1.0 if parts[9].strip().upper() == 'Y' else 0.0\n",
        "        trip_duration = float(parts[10])\n",
        "\n",
        "        # Tạo features\n",
        "        pickup_epoch = float(pickup_dt.timestamp())\n",
        "        dropoff_epoch = float(dropoff_dt.timestamp())\n",
        "        features = [vendor_id, pickup_epoch, dropoff_epoch, passenger_count,\n",
        "                   pickup_long, pickup_lat, dropoff_long, dropoff_lat, store_fwd]\n",
        "\n",
        "        return LabeledPoint(trip_duration, features)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return None\n",
        "\n",
        "train_parsed = train_rawData.map(parse).filter(lambda x: x is not None).cache()\n",
        "test_parsed = test_rawData.map(parse).filter(lambda x: x is not None).cache()"
      ],
      "metadata": {
        "id": "sYyFdRuZi1mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-val split"
      ],
      "metadata": {
        "id": "9O9B6wiRo8gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = train_parsed.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "a1oxx9InmvvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Decision Tree Regressor model using MLlib"
      ],
      "metadata": {
        "id": "K6dc8p6qpaAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Decision Tree model with parameters"
      ],
      "metadata": {
        "id": "cvDlNpUcprY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_model = DecisionTree.trainRegressor(\n",
        "    train_data,\n",
        "    categoricalFeaturesInfo={},\n",
        "    impurity=\"variance\",\n",
        "    maxDepth=5,\n",
        "    maxBins=32,\n",
        "    minInstancesPerNode=10\n",
        ")"
      ],
      "metadata": {
        "id": "NKFaFUAGpv_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions on validation"
      ],
      "metadata": {
        "id": "O6aAkdg9NAGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tính toán dự đoán và nhãn (trên driver)\n",
        "predictions = dt_model.predict(val_data.map(lambda x: x.features))\n",
        "\n",
        "# Chuyển thành list để tính toán thủ công (với tập nhỏ)\n",
        "labelsAndPredictions = val_data.map(lambda lp: lp.label).zip(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEdRvpSXsgFE",
        "outputId": "38221f1e-e366-493f-dbe6-be4ca1ea8401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Evaluation Results:\n",
            "Validation Set:\n",
            "Root Mean Squared Error (RMSE) = 3208.8514205671545\n",
            "R-squared (R²) = -0.02246461142531264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation model"
      ],
      "metadata": {
        "id": "xrgAHSdGNGgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_metrics(labelsAndPredictions):\n",
        "    # Tính toán các giá trị cần thiết\n",
        "    metrics = labelsAndPredictions.map(\n",
        "        lambda x: (1, x[0], x[1], (x[0] - x[1]) ** 2, abs(x[0] - x[1]), x[0] ** 2)\n",
        "    ).reduce(\n",
        "        lambda a, b: (\n",
        "            a[0] + b[0],  # count\n",
        "            a[1] + b[1],  # sum of labels\n",
        "            a[2] + b[2],  # sum of predictions\n",
        "            a[3] + b[3],  # sum of squared errors\n",
        "            a[4] + b[4],  # sum of absolute errors\n",
        "            a[5] + b[5]   # sum of squared labels (for total variance)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    n = metrics[0]\n",
        "    if n == 0:\n",
        "        return {\"RMSE\": 0, \"R2\": 0}\n",
        "\n",
        "    mse = metrics[3] / n\n",
        "    rmse = mse ** 0.5\n",
        "    mean_label = metrics[1] / n\n",
        "    ss_total = metrics[5] - n * (mean_label ** 2)\n",
        "    ss_residual = metrics[3]\n",
        "    r2 = 1 - (ss_residual / ss_total) if ss_total != 0 else 0.0\n",
        "\n",
        "    return {\"RMSE\": rmse, \"R2\": r2}\n",
        "\n",
        "metrics = evaluate_metrics(labelsAndPredictions)\n",
        "\n",
        "print(\"\\nModel Evaluation Results:\")\n",
        "print(\"Validation Set:\")\n",
        "print(\"Root Mean Squared Error (RMSE) =\", metrics[\"RMSE\"])\n",
        "print(\"R-squared (R²) =\", metrics[\"R2\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgv08w1ENLJ-",
        "outputId": "a1cf983c-0160-4208-97d0-f2fd3f4ee5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Evaluation Results:\n",
            "Validation Set:\n",
            "Root Mean Squared Error (RMSE) = 3208.8514205671545\n",
            "R-squared (R²) = -0.02246461142531264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reference**"
      ],
      "metadata": {
        "id": "onSUhdtD5FjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. [Spark Document - Decistion Tree Regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-regression)\n",
        "\n",
        "2. [Spark Document - Decision Trees(RDD-based API)](https://spark.apache.org/docs/latest/mllib-decision-tree.html)"
      ],
      "metadata": {
        "id": "Yu6KaSQI5ICj"
      }
    }
  ]
}