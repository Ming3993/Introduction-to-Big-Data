{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5529445",
   "metadata": {},
   "source": [
    "# 1. Initialize SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd3228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/05/09 10:05:45 WARN Utils: Your hostname, HuuNghia-PC resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/05/09 10:05:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/09 10:05:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CreditCardFraud_RDD_Based\").master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a5fcdf",
   "metadata": {},
   "source": [
    "# 2. Load & Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf1e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after deduplication: 283726\n",
      "Records after cleaning: 283726\n"
     ]
    }
   ],
   "source": [
    "lines = sc.textFile(\"hdfs:///hcmus/22120227/Exercises/Lab3/data/creditcard.csv\")\n",
    "header = lines.first()\n",
    "data = lines.filter(lambda row: row != header)\n",
    "\n",
    "# Remove exact duplicates\n",
    "data = data.distinct()\n",
    "print(f\"Rows after deduplication: {data.count()}\")\n",
    "\n",
    "# Remove malformed rows\n",
    "data = data.filter(lambda line: len(line.split(',')) == 31)\n",
    "print(f\"Records after cleaning: {data.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727a1774",
   "metadata": {},
   "source": [
    "# 3. Parse into (label, raw-features) tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7595610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed: (0.0, [-0.425965884412454, 0.960523044882985, 1.14110934232219, -0.168252079760302, 0.42098688077219, -0.0297275516639742, 0.476200948720027, 0.260314333074874, -0.56867137571251, -0.371407196834471, 1.34126198001957, 0.359893837038039, -0.358090652573631, -0.137133700217612, 0.517616806555742, 0.401725895589603, -0.0581328233640131, 0.0686531494425432, -0.0331937877876282, 0.0849676720682049, -0.208253514656728, -0.559824796253248, -0.0263976679795373, -0.371426583174346, -0.232793816737034, 0.105914779097957, 0.253844224739337, 0.0810802569229443, 2.0, 3.67], [2.0, -0.425965884412454, 0.960523044882985, 1.14110934232219, -0.168252079760302, 0.42098688077219, -0.0297275516639742, 0.476200948720027, 0.260314333074874, -0.56867137571251, -0.371407196834471, 1.34126198001957, 0.359893837038039, -0.358090652573631, -0.137133700217612, 0.517616806555742, 0.401725895589603, -0.0581328233640131, 0.0686531494425432, -0.0331937877876282, 0.0849676720682049, -0.208253514656728, -0.559824796253248, -0.0263976679795373, -0.371426583174346, -0.232793816737034, 0.105914779097957, 0.253844224739337, 0.0810802569229443, 3.67, 0.0])\n"
     ]
    }
   ],
   "source": [
    "def parse_to_pair(line):\n",
    "    vals = line.strip().replace('\"','').split(',')\n",
    "    raw_vals = [float(v) for v in vals]\n",
    "    features = [ float(vals[i]) for i in range(1,29) ] + [ float(vals[0]), float(vals[29]) ]\n",
    "    label = float(vals[30])\n",
    "    return (label, features, raw_vals)\n",
    "\n",
    "parsed = data.map(parse_to_pair)\n",
    "print(\"Parsed:\", parsed.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c496fb0",
   "metadata": {},
   "source": [
    "# 4. Standardize each feature dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First scaled LabeledPoint: (LabeledPoint(0.0, [-0.2217028945454752,0.5858116621248715,0.7552925575140171,-0.11687713221997206,0.3043985479000141,-0.0214636285494593,0.38642519236408757,0.2215069801184997,-0.5176440604458157,-0.34370490530557013,1.3164167007570957,0.36253934785450453,-0.3603409172432784,-0.1442804456221721,0.564627350784502,0.45847037481254743,-0.06920175394664986,0.08017648079189918,-0.04048486903719246,0.11010679473848713,-0.287167055780041,-0.772630472830473,-0.04264187474139357,-0.6136466426018291,-0.4461864250142345,0.21940606321886716,0.6369806464936855,0.24550735753670333,-1.9967772787560036,-0.3386696403466281]), [2.0, -0.425965884412454, 0.960523044882985, 1.14110934232219, -0.168252079760302, 0.42098688077219, -0.0297275516639742, 0.476200948720027, 0.260314333074874, -0.56867137571251, -0.371407196834471, 1.34126198001957, 0.359893837038039, -0.358090652573631, -0.137133700217612, 0.517616806555742, 0.401725895589603, -0.0581328233640131, 0.0686531494425432, -0.0331937877876282, 0.0849676720682049, -0.208253514656728, -0.559824796253248, -0.0263976679795373, -0.371426583174346, -0.232793816737034, 0.105914779097957, 0.253844224739337, 0.0810802569229443, 3.67, 0.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.feature import StandardScaler\n",
    "\n",
    "# Extract just the feature-vectors\n",
    "feat_rdd = parsed.map(lambda lp: Vectors.dense(lp[1]))\n",
    "\n",
    "# Fit a StandardScalerModel (with mean & std)\n",
    "scaler = StandardScaler(withMean=True, withStd=True).fit(feat_rdd)\n",
    "\n",
    "# Transform every feature-vector\n",
    "scaled_feat_rdd = scaler.transform(feat_rdd)\n",
    "\n",
    "# Zip labels back onto the scaled features\n",
    "rdd_lp = parsed.zip(scaled_feat_rdd).map(lambda x: (LabeledPoint(x[0][0], x[1]), x[0][2]))\n",
    "print(\"First scaled LabeledPoint:\", rdd_lp.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2bcdb",
   "metadata": {},
   "source": [
    "# 5. Split into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6354da85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 5) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 227339, Test size: 56387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_rdd, test_rdd = rdd_lp.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Train size: {train_rdd.count()}, Test size: {test_rdd.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f05adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the LabeledPoint objects from train_rdd\n",
    "train_lp = train_rdd.map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4085472",
   "metadata": {},
   "source": [
    "# 6. Train & Tune Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97635344",
   "metadata": {},
   "source": [
    "## 6.1. Prepare the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc0fb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "def evaluate_rdd(preds_and_labels):\n",
    "    # Compute ROC-AUC and PR-AUC\n",
    "    metrics = BinaryClassificationMetrics(preds_and_labels)\n",
    "    roc_auc = metrics.areaUnderROC\n",
    "    pr_auc = metrics.areaUnderPR\n",
    "\n",
    "    # Threshold at 0.5 to get hard predictions\n",
    "    pl = preds_and_labels.map(lambda sl: ((1.0 if sl[0] >= 0.5 else 0.0), sl[1]))\n",
    "    \n",
    "    # Confusion matrix counts\n",
    "    tp = pl.filter(lambda x: x == (1.0, 1.0)).count()\n",
    "    fp = pl.filter(lambda x: x == (1.0, 0.0)).count()\n",
    "    fn = pl.filter(lambda x: x == (0.0, 1.0)).count()\n",
    "    tn = pl.filter(lambda x: x == (0.0, 0.0)).count()\n",
    "    \n",
    "    # Classic matrics\n",
    "    accuracy  = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    \n",
    "    return {\"Accuracy\": accuracy, \"Precision\": precision,\n",
    "            \"Recall\": recall, \"F1\": f1,\n",
    "            \"ROC-AUC\": roc_auc, \"PR-AUC\": pr_auc,\n",
    "            \"ConfusionMatrix\": [[tn, fp], [fn, tp]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccfe334",
   "metadata": {},
   "source": [
    "## 6.2. LBFGS Hyperparameter Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a0e57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:06:12 WARN Instrumentation: [63a266f1] Initial coefficients will be ignored! Its dimensions (1, 30) did not match the expected size (1, 30)\n",
      "25/05/09 10:06:12 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "/home/huunghia/pyspark-env/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS(iters=50) → PR‑AUC=0.4004, F1=0.7816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:06:36 WARN Instrumentation: [e2722bd1] Initial coefficients will be ignored! Its dimensions (1, 30) did not match the expected size (1, 30)\n",
      "/home/huunghia/pyspark-env/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS(iters=100) → PR‑AUC=0.4004, F1=0.7816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:06:56 WARN Instrumentation: [c30acf81] Initial coefficients will be ignored! Its dimensions (1, 30) did not match the expected size (1, 30)\n",
      "[Stage 285:>                                                        (0 + 5) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS(iters=200) → PR‑AUC=0.4004, F1=0.7816\n",
      "\n",
      "Best LBFGS configuration:\n",
      "iterations = 50\n",
      "F1 = 0.7816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "\n",
    "# Define grid\n",
    "iters_list = [50, 100, 200]\n",
    "\n",
    "best_lbfgs = {\"f1\": 0.0, \"iters\": None}\n",
    "\n",
    "# Loop over grid and evaluate\n",
    "for iters in iters_list:\n",
    "    model = LogisticRegressionWithLBFGS.train(\n",
    "        train_lp,\n",
    "        iterations=iters,\n",
    "        numClasses=2\n",
    "    )\n",
    "    model.clearThreshold()\n",
    "    preds = test_rdd.map(lambda p: (model.predict(p[0].features), p[0].label))\n",
    "    res = evaluate_rdd(preds)\n",
    "    print(f\"LBFGS(iters={iters}) → PR‑AUC={res['PR-AUC']:.4f}, F1={res['F1']:.4f}\")\n",
    "    if res[\"F1\"] > best_lbfgs[\"f1\"]:\n",
    "        best_lbfgs.update({\"f1\": res[\"F1\"], \"iters\": iters})\n",
    "\n",
    "# Print best configuration\n",
    "print(\"\\nBest LBFGS configuration:\")\n",
    "print(f\"iterations = {best_lbfgs['iters']}\")\n",
    "print(f\"F1 = {best_lbfgs['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e22ab6",
   "metadata": {},
   "source": [
    "## 6.3. SGD Hyperparameter Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74105e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huunghia/pyspark-env/lib/python3.12/site-packages/pyspark/mllib/classification.py:395: FutureWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
      "  warnings.warn(\n",
      "25/05/09 10:07:19 WARN GradientDescent: Testing against a convergenceTol when using miniBatchFraction < 1.0 can be unstable because of the stochasticity in sampling.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(iters=50, step=10) → PR‑AUC=0.7180, F1=0.0524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:07:39 WARN GradientDescent: Testing against a convergenceTol when using miniBatchFraction < 1.0 can be unstable because of the stochasticity in sampling.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(iters=50, step=15) → PR‑AUC=0.7194, F1=0.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:08:03 WARN GradientDescent: Testing against a convergenceTol when using miniBatchFraction < 1.0 can be unstable because of the stochasticity in sampling.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(iters=50, step=20) → PR‑AUC=0.6932, F1=0.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:08:27 WARN GradientDescent: Testing against a convergenceTol when using miniBatchFraction < 1.0 can be unstable because of the stochasticity in sampling.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(iters=100, step=10) → PR‑AUC=0.7150, F1=0.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:08:48 WARN GradientDescent: Testing against a convergenceTol when using miniBatchFraction < 1.0 can be unstable because of the stochasticity in sampling.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(iters=100, step=15) → PR‑AUC=0.7173, F1=0.1487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:09:12 WARN GradientDescent: Testing against a convergenceTol when using miniBatchFraction < 1.0 can be unstable because of the stochasticity in sampling.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(iters=100, step=20) → PR‑AUC=0.7200, F1=0.1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:09:37 WARN GradientDescent: Testing against a convergenceTol when using miniBatchFraction < 1.0 can be unstable because of the stochasticity in sampling.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(iters=200, step=10) → PR‑AUC=0.7200, F1=0.0802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:10:05 WARN GradientDescent: Testing against a convergenceTol when using miniBatchFraction < 1.0 can be unstable because of the stochasticity in sampling.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(iters=200, step=15) → PR‑AUC=0.7231, F1=0.0830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:10:28 WARN GradientDescent: Testing against a convergenceTol when using miniBatchFraction < 1.0 can be unstable because of the stochasticity in sampling.\n",
      "[Stage 2790:>                                                       (0 + 5) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(iters=200, step=20) → PR‑AUC=0.7227, F1=0.0828\n",
      "\n",
      "Best SGD configuration:\n",
      "iterations = 100\n",
      "step = 20\n",
      "F1 = 0.1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "\n",
    "# Define grid\n",
    "iters_list = [50, 100, 200]\n",
    "step_list  = [10, 15, 20]\n",
    "\n",
    "best_sgd = {\"f1\": 0.0, \"iterations\": None, \"step\": None}\n",
    "\n",
    "# Loop over grid and evaluate\n",
    "for iters in iters_list:\n",
    "    for step in step_list:\n",
    "        model = LogisticRegressionWithSGD.train(\n",
    "            train_lp,\n",
    "            iterations=iters,\n",
    "            step=step,\n",
    "            miniBatchFraction=0.5\n",
    "        )\n",
    "        model.clearThreshold()\n",
    "        preds = test_rdd.map(lambda p: (model.predict(p[0].features), p[0].label))\n",
    "        res   = evaluate_rdd(preds)\n",
    "        print(f\"SGD(iters={iters}, step={step}) → PR‑AUC={res['PR-AUC']:.4f}, F1={res['F1']:.4f}\")\n",
    "        \n",
    "        if res[\"F1\"] > best_sgd[\"f1\"]:\n",
    "            best_sgd.update({\"f1\": res[\"F1\"], \"iterations\": iters, \"step\": step})\n",
    "\n",
    "# Print best configuration\n",
    "print(\"\\nBest SGD configuration:\")\n",
    "print(f\"iterations = {best_sgd['iterations']}\")\n",
    "print(f\"step = {best_sgd['step']}\")\n",
    "print(f\"F1 = {best_sgd['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2184c9ad",
   "metadata": {},
   "source": [
    "## 6.4. Model Selection\n",
    "In fraud detection, we prioritize **F1‑score** to balance catching as many fraudulent transactions as possible (recall) while minimizing false alarms (precision).  \n",
    "\n",
    "From our hyperparameter tuning:  \n",
    "- **LBFGS** achieved **F1 ≈ 0.7816**  \n",
    "- **SGD** achieved **F1 ≈ 0.1509**  \n",
    "\n",
    "Therefore, we select the **LBFGS** model for final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca98009",
   "metadata": {},
   "source": [
    "# 7. Final Retraining and Evaluation on Test Set\n",
    "Retrain the best models found in Section 7 on the full training RDD, then evaluate each on the held‑out test RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a8bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/09 10:10:54 WARN Instrumentation: [82e10172] Initial coefficients will be ignored! Its dimensions (1, 30) did not match the expected size (1, 30)\n",
      "[Stage 2881:=================================>                      (3 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LBFGS Evaluation:\n",
      "  Accuracy     = 0.9993260857999184\n",
      "  Precision    = 0.7727272726394628\n",
      "  Recall       = 0.7906976743266632\n",
      "  F1           = 0.7816091903131195\n",
      "  ROC-AUC      = 0.907388567182293\n",
      "  PR-AUC       = 0.4003566751256275\n",
      "  ConfusionMatrix = [[56281, 20], [18, 68]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "best_lbfgs_model = LogisticRegressionWithLBFGS.train(train_lp, iterations=50, numClasses=2)\n",
    "\n",
    "# Extract only the LabeledPoint objects from the test RDD\n",
    "test_lp = test_rdd.map(lambda x: x[0])  # x = (LabeledPoint, raw_vals)\n",
    "\n",
    "# Extract true labels\n",
    "test_labels = test_lp.map(lambda p: p.label)\n",
    "\n",
    "# Predict using the trained model\n",
    "best_lbfgs_model.clearThreshold()\n",
    "preds = test_lp.map(lambda p: best_lbfgs_model.predict(p.features))\n",
    "\n",
    "# Zip predictions and true labels\n",
    "preds_lbfgs = preds.zip(test_labels)\n",
    "\n",
    "# Evaluate using binary classification metrics\n",
    "res_lbfgs = evaluate_rdd(preds_lbfgs)\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Final LBFGS Evaluation:\")\n",
    "for metric, value in res_lbfgs.items():\n",
    "    print(f\"  {metric:12} = {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38668308",
   "metadata": {},
   "source": [
    "# 8. Export Full Test Data with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62400be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction file saved to: predictions_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Zip predictions with original raw values\n",
    "test_raw_vals = test_rdd.map(lambda x: x[1])  # raw features from the CSV\n",
    "test_preds = preds.map(lambda p: int(round(p)))  # Convert prediction to 0 or 1\n",
    "test_joined = test_raw_vals.zip(test_preds)\n",
    "\n",
    "# Define header: all original columns + prediction\n",
    "header = [\"Time\"] + [f\"V{i}\" for i in range(1, 29)] + [\"Amount\", \"Class\", \"prediction\"]\n",
    "header_line = \",\".join(header)\n",
    "\n",
    "# Convert each row to CSV line\n",
    "data_lines = test_joined.map(lambda row: \",\".join([str(x) for x in row[0]] + [str(row[1])])).collect()\n",
    "\n",
    "# Save locally with header first\n",
    "output_path = \"results.csv\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(header_line + \"\\n\")\n",
    "    for line in data_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Prediction file saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
