{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import essential libraries and create a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/08 17:26:03 WARN Utils: Your hostname, bigdata resolves to a loopback address: 127.0.1.1; using 172.22.193.31 instead (on interface eth0)\n",
      "25/04/08 17:26:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/08 17:26:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('asr.csv',header= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------+--------------------+----------+--------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+-----+------------+-----------+\n",
      "|index|           Order ID|    Date|              Status|Fulfilment|Sales Channel |ship-service-level|  Style|            SKU|     Category|Size|      ASIN|Courier Status|Qty|currency|Amount|  ship-city| ship-state|ship-postal-code|ship-country|       promotion-ids|  B2B|fulfilled-by|Unnamed: 22|\n",
      "+-----+-------------------+--------+--------------------+----------+--------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+-----+------------+-----------+\n",
      "|    0|405-8078784-5731545|04-30-22|           Cancelled|  Merchant|     Amazon.in|          Standard| SET389| SET389-KR-NP-S|          Set|   S|B09KXVBD7Z|          NULL|  0|     INR|647.62|     MUMBAI|MAHARASHTRA|        400081.0|          IN|                NULL|False|   Easy Ship|       NULL|\n",
      "|    1|171-9198151-1101146|04-30-22|Shipped - Deliver...|  Merchant|     Amazon.in|          Standard|JNE3781|JNE3781-KR-XXXL|        kurta| 3XL|B09K3WFS32|       Shipped|  1|     INR| 406.0|  BENGALURU|  KARNATAKA|        560085.0|          IN|Amazon PLCC Free-...|False|   Easy Ship|       NULL|\n",
      "|    2|404-0687676-7273146|04-30-22|             Shipped|    Amazon|     Amazon.in|         Expedited|JNE3371|  JNE3371-KR-XL|        kurta|  XL|B07WV4JV4D|       Shipped|  1|     INR| 329.0|NAVI MUMBAI|MAHARASHTRA|        410210.0|          IN|IN Core Free Ship...| True|        NULL|       NULL|\n",
      "|    3|403-9615377-8133951|04-30-22|           Cancelled|  Merchant|     Amazon.in|          Standard|  J0341|     J0341-DR-L|Western Dress|   L|B099NRCT7B|          NULL|  0|     INR|753.33| PUDUCHERRY| PUDUCHERRY|        605008.0|          IN|                NULL|False|   Easy Ship|       NULL|\n",
      "|    4|407-1069790-7240320|04-30-22|             Shipped|    Amazon|     Amazon.in|         Expedited|JNE3671|JNE3671-TU-XXXL|          Top| 3XL|B098714BZP|       Shipped|  1|     INR| 574.0|    CHENNAI| TAMIL NADU|        600073.0|          IN|                NULL|False|        NULL|       NULL|\n",
      "+-----+-------------------+--------+--------------------+----------+--------------+------------------+-------+---------------+-------------+----+----------+--------------+---+--------+------+-----------+-----------+----------------+------------+--------------------+-----+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Fulfilment: string (nullable = true)\n",
      " |-- Sales Channel : string (nullable = true)\n",
      " |-- ship-service-level: string (nullable = true)\n",
      " |-- Style: string (nullable = true)\n",
      " |-- SKU: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      " |-- ASIN: string (nullable = true)\n",
      " |-- Courier Status: string (nullable = true)\n",
      " |-- Qty: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- Amount: string (nullable = true)\n",
      " |-- ship-city: string (nullable = true)\n",
      " |-- ship-state: string (nullable = true)\n",
      " |-- ship-postal-code: string (nullable = true)\n",
      " |-- ship-country: string (nullable = true)\n",
      " |-- promotion-ids: string (nullable = true)\n",
      " |-- B2B: string (nullable = true)\n",
      " |-- fulfilled-by: string (nullable = true)\n",
      " |-- Unnamed: 22: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(F.lower(F.col(\"Status\")).contains(\"shipped\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Date\", F.to_date(\"Date\",\"MM-dd-yy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"report_date\", F.next_day(F.col(\"Date\"), \"Mon\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "result_df = df.groupBy(\"report_date\", \"SKU\") \\\n",
    "    .agg(F.sum(\"Qty\").alias(\"total_quantity\")) \\\n",
    "    .withColumnRenamed(\"SKU\", \"sku\") \\\n",
    "    .orderBy(\"report_date\", \"SKU\")\n",
    "    \n",
    "\n",
    "result_df = result_df.withColumn(\"total_quantity\", col(\"total_quantity\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+--------------+\n",
      "|report_date|            sku|total_quantity|\n",
      "+-----------+---------------+--------------+\n",
      "| 2022-04-04| AN209-BIEGE-XL|             1|\n",
      "| 2022-04-04|BL003-50BLACK-B|             1|\n",
      "| 2022-04-04|  BL009-61BLACK|             3|\n",
      "| 2022-04-04|   BL015-63PINK|             1|\n",
      "| 2022-04-04| BL023-74PINK-B|             1|\n",
      "| 2022-04-04|  BL035-161GOLD|             4|\n",
      "| 2022-04-04|BL057-65BLACK-A|             3|\n",
      "| 2022-04-04|        BL099-L|             1|\n",
      "| 2022-04-04|        BL102-L|             1|\n",
      "| 2022-04-04|       BL103-XS|             1|\n",
      "| 2022-04-04|      BL104-XXL|             1|\n",
      "| 2022-04-04|        BL110-L|             1|\n",
      "| 2022-04-04|        BL111-L|             2|\n",
      "| 2022-04-04|        BL111-M|             1|\n",
      "| 2022-04-04|        BL113-S|             1|\n",
      "| 2022-04-04|       BL113-XS|             1|\n",
      "| 2022-04-04|    BTM029-NP-L|             1|\n",
      "| 2022-04-04|    BTM029-NP-S|             1|\n",
      "| 2022-04-04|   BTM032-NP-XS|             1|\n",
      "| 2022-04-04|    BTM047-PP-L|             1|\n",
      "+-----------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+--------------+\n",
      "|report_date|            sku|total_quantity|\n",
      "+-----------+---------------+--------------+\n",
      "| 2022-04-04| AN209-BIEGE-XL|             1|\n",
      "| 2022-04-04|BL003-50BLACK-B|             1|\n",
      "| 2022-04-04|  BL009-61BLACK|             3|\n",
      "| 2022-04-04|   BL015-63PINK|             1|\n",
      "| 2022-04-04| BL023-74PINK-B|             1|\n",
      "| 2022-04-04|  BL035-161GOLD|             4|\n",
      "| 2022-04-04|BL057-65BLACK-A|             3|\n",
      "| 2022-04-04|        BL099-L|             1|\n",
      "| 2022-04-04|        BL102-L|             1|\n",
      "| 2022-04-04|       BL103-XS|             1|\n",
      "| 2022-04-04|      BL104-XXL|             1|\n",
      "| 2022-04-04|        BL110-L|             1|\n",
      "| 2022-04-04|        BL111-L|             2|\n",
      "| 2022-04-04|        BL111-M|             1|\n",
      "| 2022-04-04|        BL113-S|             1|\n",
      "| 2022-04-04|       BL113-XS|             1|\n",
      "| 2022-04-04|    BTM029-NP-L|             1|\n",
      "| 2022-04-04|    BTM029-NP-S|             1|\n",
      "| 2022-04-04|   BTM032-NP-XS|             1|\n",
      "| 2022-04-04|    BTM047-PP-L|             1|\n",
      "+-----------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_df = spark.read.csv('../../src/Task_2.2/output.csv',header= True)\n",
    "\n",
    "main_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+--------------+\n",
      "|report_date|sku|total_quantity|\n",
      "+-----------+---+--------------+\n",
      "+-----------+---+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Dòng có trong df1 nhưng không có trong df2\n",
    "diff1 = main_df.subtract(result_df)\n",
    "\n",
    "# Dòng có trong df2 nhưng không có trong df1\n",
    "diff2 = result_df.subtract(main_df)\n",
    "\n",
    "# Union 2 phần khác nhau lại để thấy toàn bộ dòng khác nhau\n",
    "differences = diff1.union(diff2)\n",
    "\n",
    "# In ra kết quả\n",
    "differences.show()\n",
    "\n",
    "print(differences.count())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
